> 一次关于字符串索引的探索

### 背景

线上数据库用户表有千万级的数据, 有一个会员搜索的接口要求做到模糊匹配用户昵称, 并且还有很多其他的条件, 但是最最影响查询速度的就是这个模糊匹配, 过慢的接口不仅会占用数据库资源, 还会卡住服务 (uwsgi) 进程, 进而影响整个后端服务

### 技术栈

- mysql: 5.6
- django: 2.2

### Elasticsearch

既然是用于搜索的, 首先考虑上 es. 

试行一段时间后, 搜索速度是很快, 效果也不错, 但是在同步数据方面消耗的资源太大了. 由于业务上要求对用户的登录时间做排序, 因此必须在用户登录的时候将用户信息同步至 es, 而千万级用户量的更新频率很高了 (除了登录外还有其他地方也需要进行同步) , 所以试行了几天后就把单机 es 的小水管撑破了, 过高的请求数占用很高的内存 (缓存), 然后触发 JVM 的熔断器, 就把大部分的请求杀掉了, 严重影响了其他依赖 es 的正常业务. 后续虽然通过调整 es 参数和同步策略使 es 可以正常处理业务了, 但是 CTO 觉得目前的业务不适合使用 es, 还是要调回使用数据库查询才行.



### 全文索引

mysql 支持全文索引, 于是先在本地导了份数据做测试, 测试结果很不错, 索引正常工作, 而且 django orm 也是支持全文索引查询的 (search), 不需要额外去改动 sql 语句.

```sql
# 创建全文索引
alter table user add fulltext index content_tag_fulltext(nick_name);
# 使用全文索引
select * from user where match(nick_name) against('xxx');
```

测试过程中可能会发现搜索 'a' 但是昵称为 'aaa' 的结果出不来, 这是因为全文索引有一个 *搜索长度* 的配置, InnoDB 引擎默认最小值是3, 也就是说只会对长度大于 3 的记录做索引, 我们需要修改这一配置并重建索引.

```
// MyISAM
ft_min_word_len = 4;
ft_max_word_len = 84;

// InnoDB
innodb_ft_min_token_size = 3;
innodb_ft_max_token_size = 84;
```



部署到测试环境的时候发现了问题: 英文的搜索可以正常进行, 但是中文的怎么也搜索不出来, 除非全文匹配.

Google 一番后发现 mysql5.6 版本开始支持全文索引, 但是到 5.7 分词器才支持中文, 也就是说要使用全文索引只能把数据库版本升级到 5.7

升级数据库版本需要出方案评估升级可能带来的业务影响, 时间上来不及. 最后和产品方面协商暂时只支持到前缀匹配



### 普通索引

> 字符串的普通索引只支持前缀匹配

本来是很简单的东西了, 没想到还是踩了个坑.

django orm 前缀匹配是 (i)startswith, 第一版是用的 startswith, 即区分大小写, 对应的 sql 是这样的:

```sql
select * from user where nick_name like binary 'xxx%';
```

注意关键字 BINARY, 它对 nick_name 做了一次类型转换, 导致索引用不上, 所以这个搜索还是巨慢.

后面改成了 istartswith, 即不区分大小写, 才正常用上了索引:

```sql
select * from user where nick_name like 'xxx%';
```

> mysql 中很多种情况会导致索引失效, 实际使用的时候需要尽量规避掉这些情况.

### 后记

后续用户要支持模糊匹配还是要从 es 或者升级数据库版本两个方向入手了.

